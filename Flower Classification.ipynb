{
  "cells": [
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "### Importing Iris Dataset "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from pandas import read_csv\nnames = ['SEPAL_LENGTH', 'SEPAL_WIDTH', 'PETAL_LENGTH', \"PETAL_WIDTH\", \"CLASS\"] #dataset column names, derived from https://archive.ics.uci.edu/ml/datasets/Iris\ndataset = read_csv('iris.csv', names=names) #using read_csv to import dataset",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "dataset.head() #checking data was correctly imported",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SEPAL_LENGTH</th>\n      <th>SEPAL_WIDTH</th>\n      <th>PETAL_LENGTH</th>\n      <th>PETAL_WIDTH</th>\n      <th>CLASS</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.1</td>\n      <td>3.5</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>3.6</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "   SEPAL_LENGTH  SEPAL_WIDTH  PETAL_LENGTH  PETAL_WIDTH        CLASS\n0           5.1          3.5           1.4          0.2  Iris-setosa\n1           4.9          3.0           1.4          0.2  Iris-setosa\n2           4.7          3.2           1.3          0.2  Iris-setosa\n3           4.6          3.1           1.5          0.2  Iris-setosa\n4           5.0          3.6           1.4          0.2  Iris-setosa"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "dataset.groupby('CLASS').size() #count different values within the CLASS field",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "CLASS\nIris-setosa        50\nIris-versicolor    50\nIris-virginica     50\ndtype: int64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Split Dataset Into Training and Testing Partitions"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split\n\nx_values = dataset.values[:,0:4] #grab all the data except the last column\ny_values = dataset.values[:, 4] #grab the last column of data\n\n#Below split data via an 80/20 split (80% train data, 20% test data) - commonly done on most datasets\n#random_state shuffles the data before applying the split\ntrain_x, test_x, train_y, test_y = train_test_split(x_values, y_values, test_size=0.2, random_state=1)",
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Creating Models"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Dataset will require supervised learning techniques to be applied to it\n#The following code will apply a range of algorithms to determine the best possible choice\n#according to the model's accuracy\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\n\nmodel_1 = SVC(gamma='auto') #model using Support Vector Classification algorithm\nmodel_2 = LogisticRegression(solver='liblinear', multi_class='ovr') #model using Logistic Regression Classifier algorithm\nmodel_3 = DecisionTreeClassifier() #model using Decision Tree Classifier algorithm",
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Testing Models"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import StratifiedKFold\n#Using cross validation (10-fold) technique to evaluate models (estimate their accuracy)\n#Cross validation helps to reduce bias\n\n#test_model_accuracy method uses cross validation methods from sklearn\n#It works in the following way:\n# 1. Shuffle data randomly\n# 2. Splits data into 10 groups. \n# 3. For each group: \n#   3.1 Pick one group as test dataset, treat rest as training datasets\n#   3.2 Apply model to training sets and evaluate on the test set\n# 4. Return mean of evaluation scores\ndef test_model_accuracy(model):\n    k_fold = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\n    result = cross_val_score(model, train_x, train_y, cv=k_fold, scoring='accuracy')\n    return result.mean()\n\n#Print the estimated accuracy of each model\nprint(\"SVC Model: \" + str(test_model_accuracy(model_1)))\nprint(\"LR Model: \" + str(test_model_accuracy(model_2)))\nprint(\"DTC Model: \" + str(test_model_accuracy(model_3)))\n#May vary slightly - but the SVC model proves to be the best model with 98% accuracy\n#The LR and DTC Models are very similar with ~95% accuracy",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": "SVC Model: 0.9833333333333332\nLR Model: 0.9559090909090908\nDTC Model: 0.951165501165501\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Making predictions with SVM Model"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\n\nfinal_model = model_1\nfinal_model.fit(train_x, train_y) #Fitting model on training dataset\npredictions = final_model.predict(test_x) #Make predictions on the test dataset\n\nprint(accuracy_score(test_y, predictions)) #Returns accuracy of the model's predictions\nprint(confusion_matrix(test_y, predictions)) #Creates a confusion matrix based on the model's predictions\n#With the confusion matrix, want more values along the diagonal (from top-left to bottom-right)\n#and few values elsewhere (these values represent incorrect classifications)\n\n#Accuracy of ~97% on test data\n#Model is not overfitted or underfitted (as high prediction accuracy on test data)",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": "0.9666666666666667\n[[11  0  0]\n [ 0 12  1]\n [ 0  0  6]]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Additional Prediction Analysis"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import classification_report\n\nprint(classification_report(test_y, predictions))\n#Below formulas derived from https://tinyurl.com/ycp3vncm\n\n#Precision = TruePositives/(TruePositives + FalsePositives)\n#Precision of 1 (no false positives) for both Setosa and Versicolor flowers\n#Some false positives produced for Virginica flower\n\n#Recall = TruePositives/(TruePositives + FalseNegatives)\n#Iris-Setosa has no false negatives or false positives - perfect prediction\n#Iris-Versicolor had 1 false negative (also determined from confusion matrix)\n#Iris-Virginica had no false negatives\n\n#F1-score = 2*(Recall * Precision)/(Recall + Precision)",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": "                 precision    recall  f1-score   support\n\n    Iris-setosa       1.00      1.00      1.00        11\nIris-versicolor       1.00      0.92      0.96        13\n Iris-virginica       0.86      1.00      0.92         6\n\n      micro avg       0.97      0.97      0.97        30\n      macro avg       0.95      0.97      0.96        30\n   weighted avg       0.97      0.97      0.97        30\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}